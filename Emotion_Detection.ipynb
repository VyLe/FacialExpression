{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FacialExpression-alignedimage.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VyLe/FacialExpression/blob/master/Emotion_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzBLRk0axjwf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Skip training\n",
        "skip_training = True #Update to True for Test Data "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_39BeAYuXPj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, os.path\n",
        "from google.colab import drive\n",
        "import zipfile \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "import random \n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-aukBYAxUIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Select device for training\n",
        "device = torch.device(\"cuda\")\n",
        "if skip_training:\n",
        "    # The models are always evaluated on CPU\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ss87DZB6k5KZ",
        "colab_type": "text"
      },
      "source": [
        "# Data Loading   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSE4hFCyr2I9",
        "colab_type": "code",
        "outputId": "d2bd90fd-ebd1-4dbb-d20c-b53571ff5365",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "#Import dataset from Google Drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "data_dir = '/content/gdrive/My Drive/DLProject/'\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxL3pvOBs7mn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#LABEL DATA\n",
        "label_dir = os.path.join(data_dir, 'basic',  'EmoLabel')\n",
        "labelfile = \"list_patition_label.txt\"\n",
        "labels = pd.read_csv(os.path.join(label_dir, labelfile), index_col=False, sep = \" \", header = None, names = ['File', 'emotion'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJxWBusX1c6y",
        "colab_type": "code",
        "outputId": "65ffb652-3621-4625-f09f-12880af70f61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "'''\n",
        "print(os.getcwd())\n",
        "\n",
        "#IMAGE DATA\n",
        "#Put image data into subfolders by each classes\n",
        "emotion = {1: 'surprise', 2: 'fear', 3: 'disgust', 4: 'happiness', 5: 'sadness', 6: 'anger', 7: 'neutral'}\n",
        "folderpath = '/content/gdrive/My Drive/DLProject/Images_aligned/aligned/'\n",
        "tofolder = '/content/gdrive/My Drive/DLProject/'\n",
        "\n",
        "#Create new folder for each label\n",
        "for i in ['train', 'test']:\n",
        "  for j in emotion.keys(): \n",
        "    os.makedirs(os.path.join(tofolder, i, str(emotion[j])))\n",
        "\n",
        "\n",
        "#Iterate over zipfile, extract images and save to corresponding label folders\n",
        "count_test = 0\n",
        "count_train = 0\n",
        "\n",
        "for filename in os.listdir(folderpath):\n",
        "    if filename != '/content':\n",
        "          imgname = os.path.basename(filename).replace('_aligned','').replace(' (1)',\"\")\n",
        "          img = Image.open(os.path.join(folderpath,filename))\n",
        "          label = labels[labels['File']==imgname]['emotion'] #Match label of the image\n",
        "          print(filename,label, count_test, count_train)\n",
        "          if 'test' in imgname:\n",
        "            img.save(os.path.join(tofolder, 'test', str(emotion[int(label)]), imgname))\n",
        "            count_test +=1\n",
        "          else:\n",
        "            img.save(os.path.join(tofolder, 'train', str(emotion[int(label)]), imgname))\n",
        "            count_train += 1\n",
        "            \n",
        "print(\"Finished. Count test: \", count_test, '. Count train: ',count_train)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nprint(os.getcwd())\\n\\n#IMAGE DATA\\n#Put image data into subfolders by each classes\\nemotion = {1: \\'surprise\\', 2: \\'fear\\', 3: \\'disgust\\', 4: \\'happiness\\', 5: \\'sadness\\', 6: \\'anger\\', 7: \\'neutral\\'}\\nfolderpath = \\'/content/gdrive/My Drive/DLProject/Images_aligned/aligned/\\'\\ntofolder = \\'/content/gdrive/My Drive/DLProject/\\'\\n\\n#Create new folder for each label\\nfor i in [\\'train\\', \\'test\\']:\\n  for j in emotion.keys(): \\n    os.makedirs(os.path.join(tofolder, i, str(emotion[j])))\\n\\n\\n#Iterate over zipfile, extract images and save to corresponding label folders\\ncount_test = 0\\ncount_train = 0\\n\\nfor filename in os.listdir(folderpath):\\n    if filename != \\'/content\\':\\n          imgname = os.path.basename(filename).replace(\\'_aligned\\',\\'\\').replace(\\' (1)\\',\"\")\\n          img = Image.open(os.path.join(folderpath,filename))\\n          label = labels[labels[\\'File\\']==imgname][\\'emotion\\'] #Match label of the image\\n          print(filename,label, count_test, count_train)\\n          if \\'test\\' in imgname:\\n            img.save(os.path.join(tofolder, \\'test\\', str(emotion[int(label)]), imgname))\\n            count_test +=1\\n          else:\\n            img.save(os.path.join(tofolder, \\'train\\', str(emotion[int(label)]), imgname))\\n            count_train += 1\\n            \\nprint(\"Finished. Count test: \", count_test, \\'. Count train: \\',count_train)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4-FuqJ2k16V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Read train and test dataset \n",
        "TRAIN_DATA_PATH = \"/content/gdrive/My Drive/DLProject/train\"\n",
        "TEST_DATA_PATH = \"/content/gdrive/My Drive/DLProject/test\"\n",
        "TRANSFORM_IMG = transforms.Compose([\n",
        "    transforms.Resize(100,100),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,), (0.5,))\n",
        "    ])\n",
        "\n",
        "train_data = torchvision.datasets.ImageFolder(root=TRAIN_DATA_PATH, transform=TRANSFORM_IMG)\n",
        "train_loader = data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "test_data = torchvision.datasets.ImageFolder(root=TEST_DATA_PATH, transform=TRANSFORM_IMG)\n",
        "test_loader  = data.DataLoader(test_data, batch_size=5, shuffle=False) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HICMa-IkUS-",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "# DATA DESCRIPTION \n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKQvcafMkTpu",
        "colab_type": "code",
        "outputId": "908cee6b-f3cd-4931-9784-58ee3c4e3178",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "print(\"Number of train samples: \", len(train_data))\n",
        "print(\"Number of test samples: \", len(test_data))\n",
        "print(\"Detected Classes are: \", train_data.class_to_idx) # classes are detected by folder structure\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of train samples:  12271\n",
            "Number of test samples:  3068\n",
            "Detected Classes are:  {'anger': 0, 'disgust': 1, 'fear': 2, 'happiness': 3, 'neutral': 4, 'sadness': 5, 'surprise': 6}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sp_8yUsJxvlW",
        "colab_type": "text"
      },
      "source": [
        "# VGG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUyjpMtek2O4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VGG(nn.Module):\n",
        "    def __init__(self, n_channels=32):\n",
        "\n",
        "        super(VGG, self).__init__()\n",
        "        n = n_channels\n",
        "        #Block 1\n",
        "        self.conv11 = nn.Conv2d(3, n, 3, padding = 1) #Change 1 to 3\n",
        "        self.conv11_bn = nn.BatchNorm2d(n)\n",
        "        self.conv12 = nn.Conv2d(n, n, 3, padding = 1)\n",
        "        self.conv12_bn = nn.BatchNorm2d(n)        \n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride = 2)\n",
        "        # Add dropout \n",
        "        \n",
        "        \n",
        "        #Block 2\n",
        "        self.conv21 = nn.Conv2d(n, 2*n, 3, padding = 1)\n",
        "        self.conv21_bn = nn.BatchNorm2d(2*n)\n",
        "        self.conv22 = nn.Conv2d(2*n, 2*n, 3, padding = 1)\n",
        "        self.conv22_bn = nn.BatchNorm2d(2*n)\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride = 2)       \n",
        "\n",
        "        self.conv3 = nn.Conv2d(2*n, 3*n, 3)\n",
        "        self.conv3_bn = nn.BatchNorm2d(3*n)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(3*n, 2*n, 1)\n",
        "        self.conv4_bn = nn.BatchNorm2d(2*n)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(2*n, n, 1)\n",
        "        self.conv5_bn = nn.BatchNorm2d(n)\n",
        "\n",
        "        self.avgpool = nn.AvgPool2d(kernel_size = 5)\n",
        "                \n",
        "        self.fc1 = nn.Linear(512, 256)\n",
        "        self.fc2 = nn.Linear(256, 7)\n",
        "\n",
        "\n",
        "    def forward(self, x, verbose=False):\n",
        "        if verbose: print(x.shape)\n",
        "        x = F.relu(self.conv11_bn(self.conv11(x)))\n",
        "        x = F.relu(self.conv12_bn(self.conv12(x)))\n",
        "\n",
        "        if verbose: print(\"conv1\", x.shape)\n",
        "        x = self.maxpool1(x)\n",
        "        if verbose: print('maxpool1:', x.shape)\n",
        "\n",
        "        x = F.relu(self.conv21_bn(self.conv21(x)))\n",
        "        x = F.relu(self.conv22_bn(self.conv22(x)))\n",
        "        if verbose: print('conv2', x.shape)\n",
        "        x = self.maxpool2(x)\n",
        "        if verbose: print('maxpool2:', x.shape)\n",
        "        \n",
        "        x = F.relu(self.conv3_bn(self.conv3(x)))\n",
        "        if verbose: print('conv3', x.shape)\n",
        "\n",
        "        x = F.relu(self.conv4_bn(self.conv4(x)))\n",
        "        if verbose: print('conv4',x.shape)\n",
        "\n",
        "        x = F.relu(self.conv5_bn(self.conv5(x)))\n",
        "        if verbose: print('conv5',x.shape)\n",
        "          \n",
        "        x = self.avgpool(x)\n",
        "        if verbose: print('avgpool:', x.shape)\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        if verbose: print('x flatten:', x.shape)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        if verbose: print('out :', x.shape)\n",
        "\n",
        "        return x "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVa1BxF1wRJH",
        "colab_type": "code",
        "outputId": "2780ee47-d25a-4224-ff6b-4b7b5ede4080",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "#Testing the shape of output \n",
        "net = VGG()\n",
        "net.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    dataiter = iter(train_loader)\n",
        "    images, labels = dataiter.next()\n",
        "    images = images.to(device)\n",
        "    print('Shape of the input tensor:', images.shape)\n",
        "\n",
        "    y = net(images, verbose=True)\n",
        "    assert y.shape == torch.Size([32, 7]), \"Bad shape of y: y.shape={}\".format(y.shape)\n",
        "\n",
        "print('The shapes seem to be ok.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the input tensor: torch.Size([32, 3, 100, 100])\n",
            "torch.Size([32, 3, 100, 100])\n",
            "conv1 torch.Size([32, 32, 100, 100])\n",
            "maxpool1: torch.Size([32, 32, 50, 50])\n",
            "conv2 torch.Size([32, 64, 50, 50])\n",
            "maxpool2: torch.Size([32, 64, 25, 25])\n",
            "conv3 torch.Size([32, 96, 23, 23])\n",
            "conv4 torch.Size([32, 64, 23, 23])\n",
            "conv5 torch.Size([32, 32, 23, 23])\n",
            "avgpool: torch.Size([32, 32, 4, 4])\n",
            "x flatten: torch.Size([32, 512])\n",
            "out : torch.Size([32, 7])\n",
            "The shapes seem to be ok.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFxz4uHw-UOx",
        "colab_type": "text"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE8_bYmJoLBX",
        "colab_type": "code",
        "outputId": "4b097964-856c-4c40-db9a-60218702cb5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCbttsmqkLTy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_accuracy(net, testloader):\n",
        "    net.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return correct / total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cjqinKhkk_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn.metrics as skmetrics\n",
        "import seaborn as sns\n",
        "classes = ['anger', 'disgust', 'fear', 'happiness', 'neutral', 'sadness', 'surprise']\n",
        "\n",
        "def confusion_matrix(net, testloader):\n",
        "    net.eval()\n",
        "    true_labels = []\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = net(images)\n",
        "            predicted = torch.argmax(outputs.data, 1)\n",
        "            true_labels.append(labels.cpu().numpy())\n",
        "            predictions.append(predicted.cpu().numpy())\n",
        "    true_labels = np.hstack(true_labels)\n",
        "    predictions = np.hstack(predictions)\n",
        "\n",
        "    c_matrix = skmetrics.confusion_matrix(true_labels, predictions)\n",
        "    figure = plt.figure(figsize=(6, 6))\n",
        "    plt.title(\"Confusion matrix\")\n",
        "    sns.heatmap(c_matrix, cmap='Blues', annot=True, xticklabels=classes, yticklabels=classes, fmt='g', cbar=False)\n",
        "    plt.xlabel('predictions')\n",
        "    plt.ylabel('true labels')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OI7AGVMt-TFR",
        "colab_type": "code",
        "outputId": "9b8c4bf5-f664-40fd-dd1e-a10e215343b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "net = VGG()\n",
        "net.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
        "n_epochs = 20\n",
        "\n",
        "net.train()\n",
        "for epoch in range(n_epochs):\n",
        "    running_loss = 0.0\n",
        "    print_every = 200  # mini-batches\n",
        "    for i, (inputs, labels) in enumerate(train_loader, 0):\n",
        "        # Transfer to GPU\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if (i % print_every) == (print_every-1):\n",
        "            print('[%d, %5d] loss: %.3f' % (epoch+1, i+1, running_loss/print_every))\n",
        "            running_loss = 0.0\n",
        "        if skip_training:\n",
        "            break\n",
        "\n",
        "    # Print accuracy after every epoch\n",
        "    accuracy= compute_accuracy(net, test_loader)\n",
        "    print('Accuracy of the network on the 3068 test images: %d %%' % (100 * accuracy))\n",
        "\n",
        "    if skip_training:\n",
        "        break\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   200] loss: 1.628\n",
            "Accuracy of the network on the 3068 test images: 50 %\n",
            "[2,   200] loss: 1.413\n",
            "Accuracy of the network on the 3068 test images: 56 %\n",
            "[3,   200] loss: 1.222\n",
            "Accuracy of the network on the 3068 test images: 59 %\n",
            "[4,   200] loss: 1.151\n",
            "Accuracy of the network on the 3068 test images: 61 %\n",
            "[5,   200] loss: 1.052\n",
            "Accuracy of the network on the 3068 test images: 64 %\n",
            "[6,   200] loss: 0.974\n",
            "Accuracy of the network on the 3068 test images: 64 %\n",
            "[7,   200] loss: 0.948\n",
            "Accuracy of the network on the 3068 test images: 66 %\n",
            "[8,   200] loss: 0.904\n",
            "Accuracy of the network on the 3068 test images: 66 %\n",
            "[9,   200] loss: 0.863\n",
            "Accuracy of the network on the 3068 test images: 67 %\n",
            "[10,   200] loss: 0.835\n",
            "Accuracy of the network on the 3068 test images: 69 %\n",
            "[11,   200] loss: 0.784\n",
            "Accuracy of the network on the 3068 test images: 69 %\n",
            "[12,   200] loss: 0.793\n",
            "Accuracy of the network on the 3068 test images: 70 %\n",
            "[13,   200] loss: 0.739\n",
            "Accuracy of the network on the 3068 test images: 69 %\n",
            "[14,   200] loss: 0.726\n",
            "Accuracy of the network on the 3068 test images: 69 %\n",
            "[15,   200] loss: 0.704\n",
            "Accuracy of the network on the 3068 test images: 71 %\n",
            "[16,   200] loss: 0.695\n",
            "Accuracy of the network on the 3068 test images: 71 %\n",
            "[17,   200] loss: 0.661\n",
            "Accuracy of the network on the 3068 test images: 71 %\n",
            "[18,   200] loss: 0.659\n",
            "Accuracy of the network on the 3068 test images: 70 %\n",
            "[19,   200] loss: 0.627\n",
            "Accuracy of the network on the 3068 test images: 72 %\n",
            "[20,   200] loss: 0.604\n",
            "Accuracy of the network on the 3068 test images: 69 %\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNkBSEbMs1We",
        "colab_type": "code",
        "outputId": "13375fee-57c0-462b-d173-41fc09af03e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "confusion_matrix(net, test_loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAGDCAYAAAB+2YQ1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHykAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4hvkh0w_RL4",
        "colab_type": "code",
        "outputId": "2405ed8f-dba5-4ce6-91da-e1682a2090b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        }
      },
      "source": [
        "#Save model \n",
        "filename = os.path.join(data_dir,'vgg_aligned.pth')\n",
        "if not skip_training:\n",
        "    try:\n",
        "        do_save = input('Do you want to save the model (type yes to confirm)? ').lower()\n",
        "        if do_save == 'yes':\n",
        "            torch.save(net.state_dict(), filename)\n",
        "            print('Model saved to %s' % filename)\n",
        "        else:\n",
        "            print('Model not saved')\n",
        "    except:\n",
        "        raise Exception('The notebook should be run or validated with skip_training=True.')\n",
        "else:\n",
        "    net = VGG()\n",
        "    net.load_state_dict(torch.load(filename, map_location=lambda storage, loc: storage))\n",
        "    net.to(device)\n",
        "    print('Model loaded from %s' % filename)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model loaded from /content/gdrive/My Drive/DLProject/vgg_aligned.pth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEUhYy0wniC3",
        "colab_type": "text"
      },
      "source": [
        "# Fine Tuning \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjW6d8VoOCTx",
        "colab_type": "code",
        "outputId": "88af42ed-004c-4637-c1f4-72284b8ed73f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "net = VGG()\n",
        "net.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
        "n_epochs = 20\n",
        "\n",
        "net.train()\n",
        "for epoch in range(n_epochs):\n",
        "    running_loss = 0.0\n",
        "    print_every = 200  # mini-batches\n",
        "    for i, (inputs, labels) in enumerate(train_loader, 0):\n",
        "        # Transfer to GPU\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if (i % print_every) == (print_every-1):\n",
        "            print('[%d, %5d] loss: %.3f' % (epoch+1, i+1, running_loss/print_every))\n",
        "            running_loss = 0.0\n",
        "        if skip_training:\n",
        "            break\n",
        "\n",
        "    # Print accuracy after every epoch\n",
        "    accuracy = compute_accuracy(net, test_loader)\n",
        "    print('Accuracy of the network on the 3068 test images: %d %%' % (100 * accuracy))\n",
        "\n",
        "    if skip_training:\n",
        "        break\n",
        "\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-24897264a78c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dl0I0czR418v",
        "colab_type": "code",
        "outputId": "70a2dcf4-06fc-4e7a-fb66-e68eb4cd743d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "#Save model \n",
        "skip_training = True \n",
        "filename = os.path.join(data_dir,'vgg_SGD.pth')\n",
        "if not skip_training:\n",
        "    try:\n",
        "        do_save = input('Do you want to save the model (type yes to confirm)? ').lower()\n",
        "        if do_save == 'yes':\n",
        "            torch.save(net.state_dict(), filename)\n",
        "            print('Model saved to %s' % filename)\n",
        "        else:\n",
        "            print('Model not saved')\n",
        "    except:\n",
        "        raise Exception('The notebook should be run or validated with skip_training=True.')\n",
        "else:\n",
        "    net_SGD = VGG()\n",
        "    net_SGD.load_state_dict(torch.load(filename, map_location=lambda storage, loc: storage))\n",
        "    net_SGD.to(device)\n",
        "    print('Model loaded from %s' % filename)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model loaded from /content/gdrive/My Drive/DLProject/vgg_SGD.pth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLf16khOkjA9",
        "colab_type": "code",
        "outputId": "59feea54-9e39-4cb3-f582-8635f58d0172",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        }
      },
      "source": [
        "print(compute_accuracy(net_SGD, test_loader))\n",
        "confusion_matrix(net_SGD, test_loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.728161668839635\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAGDCAYAAAB+2YQ1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzjmXSJ6gnHPOJZInKOecc4n0H06VJo6YaJbJAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2viM_XrpN9h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Hyperparameter tuning \n",
        "\n",
        "import gc\n",
        "gc.collect()\n",
        "import itertools\n",
        "\n",
        "\n",
        "def grid_search(*iterables):\n",
        "\n",
        "    return itertools.product(*iterables)\n",
        "\n",
        "\n",
        "def train(learning_rate, optimizer, number_epochs, wd):\n",
        "  net_tunning = VGG()\n",
        "  net_tunning.to(device)\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optimizer(net_tunning.parameters(), lr=learning_rate, weight_decay = wd)\n",
        "  n_epochs = number_epochs\n",
        "  \n",
        "  test_accuracy_history = []\n",
        "  test_errors = []  # Keep track of the test error\n",
        "\n",
        "  net_tunning.train()\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "      running_loss = 0.0\n",
        "      print_every = 200\n",
        "      for i, (inputs, labels) in enumerate(train_loader, 0):\n",
        "          # Transfer to GPU\n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "          # zero the parameter gradients\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          # forward + backward + optimize\n",
        "          outputs = net_tunning(inputs)\n",
        "          loss = criterion(outputs, labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          running_loss += loss.item()\n",
        "\n",
        "          if (i % print_every) == (print_every-1):\n",
        "            print('[%d, %5d] loss: %.3f' % (epoch+1, i+1, running_loss/print_every))\n",
        "            running_loss = 0.0\n",
        "\n",
        "          if skip_training:\n",
        "            break\n",
        "      # Print accuracy after every epoch\n",
        "      accuracy = compute_accuracy(net_tunning, test_loader)\n",
        "      print('Accuracy of the network on the 3068 test images: %d %%' % (100 * accuracy))\n",
        "      test_accuracy_history.append(accuracy)\n",
        "\n",
        "  print('Finished Training')\n",
        "  return net_tunning, test_accuracy_history\n",
        "  \n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKTxv8Vj7ltw",
        "colab_type": "code",
        "outputId": "007db0e7-a1b0-4430-cdaa-77081c074e4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 10523
        }
      },
      "source": [
        "lrate_range = [0.005, 0.01, 0.05]  # lower and upper boundaries for parameter 1 \n",
        "n_epochs = [50]\n",
        "optimizers = [optim.SGD]\n",
        "weightdecay = [0.001, 0.010]\n",
        "\n",
        "hyperparameters = []\n",
        "accuracies = []\n",
        "\n",
        "if not skip_training:\n",
        "    for (lrate, opt, n_epoch, wd) in grid_search(lrate_range, optimizers, n_epochs, weightdecay):\n",
        "        hyperparameters.append([lrate, opt, n_epoch, wd])\n",
        "        print('Hyperparameters: ', hyperparameters[-1])\n",
        "        network, test_accuracy_history = train(lrate, opt,  n_epoch, wd)\n",
        "        accuracies.append(test_accuracy_history[-1])\n",
        "        print('Final accuracy:', accuracies[-1])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hyperparameters:  [0.005, <class 'torch.optim.sgd.SGD'>, 50, 0.001]\n",
            "[1,   200] loss: 1.721\n",
            "Accuracy of the network on the 3068 test images: 38 %\n",
            "[2,   200] loss: 1.559\n",
            "Accuracy of the network on the 3068 test images: 48 %\n",
            "[3,   200] loss: 1.363\n",
            "Accuracy of the network on the 3068 test images: 53 %\n",
            "[4,   200] loss: 1.207\n",
            "Accuracy of the network on the 3068 test images: 58 %\n",
            "[5,   200] loss: 1.060\n",
            "Accuracy of the network on the 3068 test images: 54 %\n",
            "[6,   200] loss: 0.962\n",
            "Accuracy of the network on the 3068 test images: 61 %\n",
            "[7,   200] loss: 0.880\n",
            "Accuracy of the network on the 3068 test images: 64 %\n",
            "[8,   200] loss: 0.833\n",
            "Accuracy of the network on the 3068 test images: 65 %\n",
            "[9,   200] loss: 0.801\n",
            "Accuracy of the network on the 3068 test images: 66 %\n",
            "[10,   200] loss: 0.765\n",
            "Accuracy of the network on the 3068 test images: 71 %\n",
            "[11,   200] loss: 0.708\n",
            "Accuracy of the network on the 3068 test images: 71 %\n",
            "[12,   200] loss: 0.684\n",
            "Accuracy of the network on the 3068 test images: 72 %\n",
            "[13,   200] loss: 0.659\n",
            "Accuracy of the network on the 3068 test images: 70 %\n",
            "[14,   200] loss: 0.640\n",
            "Accuracy of the network on the 3068 test images: 72 %\n",
            "[15,   200] loss: 0.616\n",
            "Accuracy of the network on the 3068 test images: 69 %\n",
            "[16,   200] loss: 0.566\n",
            "Accuracy of the network on the 3068 test images: 73 %\n",
            "[17,   200] loss: 0.555\n",
            "Accuracy of the network on the 3068 test images: 67 %\n",
            "[18,   200] loss: 0.533\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[19,   200] loss: 0.500\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[20,   200] loss: 0.495\n",
            "Accuracy of the network on the 3068 test images: 70 %\n",
            "[21,   200] loss: 0.469\n",
            "Accuracy of the network on the 3068 test images: 74 %\n",
            "[22,   200] loss: 0.442\n",
            "Accuracy of the network on the 3068 test images: 74 %\n",
            "[23,   200] loss: 0.419\n",
            "Accuracy of the network on the 3068 test images: 73 %\n",
            "[24,   200] loss: 0.385\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[25,   200] loss: 0.372\n",
            "Accuracy of the network on the 3068 test images: 71 %\n",
            "[26,   200] loss: 0.348\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[27,   200] loss: 0.324\n",
            "Accuracy of the network on the 3068 test images: 72 %\n",
            "[28,   200] loss: 0.317\n",
            "Accuracy of the network on the 3068 test images: 73 %\n",
            "[29,   200] loss: 0.289\n",
            "Accuracy of the network on the 3068 test images: 73 %\n",
            "[30,   200] loss: 0.294\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[31,   200] loss: 0.263\n",
            "Accuracy of the network on the 3068 test images: 72 %\n",
            "[32,   200] loss: 0.234\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[33,   200] loss: 0.215\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[34,   200] loss: 0.218\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[35,   200] loss: 0.195\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[36,   200] loss: 0.194\n",
            "Accuracy of the network on the 3068 test images: 68 %\n",
            "[37,   200] loss: 0.175\n",
            "Accuracy of the network on the 3068 test images: 76 %\n",
            "[38,   200] loss: 0.148\n",
            "Accuracy of the network on the 3068 test images: 70 %\n",
            "[39,   200] loss: 0.158\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[40,   200] loss: 0.136\n",
            "Accuracy of the network on the 3068 test images: 74 %\n",
            "[41,   200] loss: 0.119\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[42,   200] loss: 0.109\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[43,   200] loss: 0.126\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[44,   200] loss: 0.105\n",
            "Accuracy of the network on the 3068 test images: 73 %\n",
            "[45,   200] loss: 0.098\n",
            "Accuracy of the network on the 3068 test images: 74 %\n",
            "[46,   200] loss: 0.102\n",
            "Accuracy of the network on the 3068 test images: 76 %\n",
            "[47,   200] loss: 0.094\n",
            "Accuracy of the network on the 3068 test images: 71 %\n",
            "[48,   200] loss: 0.114\n",
            "Accuracy of the network on the 3068 test images: 76 %\n",
            "[49,   200] loss: 0.096\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[50,   200] loss: 0.075\n",
            "Accuracy of the network on the 3068 test images: 76 %\n",
            "Finished Training\n",
            "Final accuracy: 0.7630378096479792\n",
            "Hyperparameters:  [0.005, <class 'torch.optim.sgd.SGD'>, 50, 0.01]\n",
            "[1,   200] loss: 1.728\n",
            "Accuracy of the network on the 3068 test images: 38 %\n",
            "[2,   200] loss: 1.558\n",
            "Accuracy of the network on the 3068 test images: 47 %\n",
            "[3,   200] loss: 1.370\n",
            "Accuracy of the network on the 3068 test images: 48 %\n",
            "[4,   200] loss: 1.232\n",
            "Accuracy of the network on the 3068 test images: 61 %\n",
            "[5,   200] loss: 1.101\n",
            "Accuracy of the network on the 3068 test images: 62 %\n",
            "[6,   200] loss: 1.004\n",
            "Accuracy of the network on the 3068 test images: 66 %\n",
            "[7,   200] loss: 0.942\n",
            "Accuracy of the network on the 3068 test images: 63 %\n",
            "[8,   200] loss: 0.876\n",
            "Accuracy of the network on the 3068 test images: 65 %\n",
            "[9,   200] loss: 0.853\n",
            "Accuracy of the network on the 3068 test images: 69 %\n",
            "[10,   200] loss: 0.804\n",
            "Accuracy of the network on the 3068 test images: 70 %\n",
            "[11,   200] loss: 0.770\n",
            "Accuracy of the network on the 3068 test images: 69 %\n",
            "[12,   200] loss: 0.738\n",
            "Accuracy of the network on the 3068 test images: 71 %\n",
            "[13,   200] loss: 0.724\n",
            "Accuracy of the network on the 3068 test images: 68 %\n",
            "[14,   200] loss: 0.694\n",
            "Accuracy of the network on the 3068 test images: 71 %\n",
            "[15,   200] loss: 0.677\n",
            "Accuracy of the network on the 3068 test images: 70 %\n",
            "[16,   200] loss: 0.650\n",
            "Accuracy of the network on the 3068 test images: 72 %\n",
            "[17,   200] loss: 0.638\n",
            "Accuracy of the network on the 3068 test images: 71 %\n",
            "[18,   200] loss: 0.635\n",
            "Accuracy of the network on the 3068 test images: 71 %\n",
            "[19,   200] loss: 0.611\n",
            "Accuracy of the network on the 3068 test images: 73 %\n",
            "[20,   200] loss: 0.595\n",
            "Accuracy of the network on the 3068 test images: 73 %\n",
            "[21,   200] loss: 0.583\n",
            "Accuracy of the network on the 3068 test images: 73 %\n",
            "[22,   200] loss: 0.557\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[23,   200] loss: 0.544\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[24,   200] loss: 0.532\n",
            "Accuracy of the network on the 3068 test images: 66 %\n",
            "[25,   200] loss: 0.515\n",
            "Accuracy of the network on the 3068 test images: 74 %\n",
            "[26,   200] loss: 0.497\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[27,   200] loss: 0.506\n",
            "Accuracy of the network on the 3068 test images: 76 %\n",
            "[28,   200] loss: 0.465\n",
            "Accuracy of the network on the 3068 test images: 74 %\n",
            "[29,   200] loss: 0.453\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[30,   200] loss: 0.447\n",
            "Accuracy of the network on the 3068 test images: 76 %\n",
            "[31,   200] loss: 0.436\n",
            "Accuracy of the network on the 3068 test images: 73 %\n",
            "[32,   200] loss: 0.430\n",
            "Accuracy of the network on the 3068 test images: 69 %\n",
            "[33,   200] loss: 0.412\n",
            "Accuracy of the network on the 3068 test images: 74 %\n",
            "[34,   200] loss: 0.396\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[35,   200] loss: 0.383\n",
            "Accuracy of the network on the 3068 test images: 71 %\n",
            "[36,   200] loss: 0.375\n",
            "Accuracy of the network on the 3068 test images: 74 %\n",
            "[37,   200] loss: 0.347\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[38,   200] loss: 0.333\n",
            "Accuracy of the network on the 3068 test images: 74 %\n",
            "[39,   200] loss: 0.328\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[40,   200] loss: 0.301\n",
            "Accuracy of the network on the 3068 test images: 74 %\n",
            "[41,   200] loss: 0.309\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[42,   200] loss: 0.291\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[43,   200] loss: 0.279\n",
            "Accuracy of the network on the 3068 test images: 74 %\n",
            "[44,   200] loss: 0.288\n",
            "Accuracy of the network on the 3068 test images: 72 %\n",
            "[45,   200] loss: 0.270\n",
            "Accuracy of the network on the 3068 test images: 76 %\n",
            "[46,   200] loss: 0.261\n",
            "Accuracy of the network on the 3068 test images: 76 %\n",
            "[47,   200] loss: 0.258\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[48,   200] loss: 0.231\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[49,   200] loss: 0.210\n",
            "Accuracy of the network on the 3068 test images: 76 %\n",
            "[50,   200] loss: 0.214\n",
            "Accuracy of the network on the 3068 test images: 76 %\n",
            "Finished Training\n",
            "Final accuracy: 0.7604302477183833\n",
            "Hyperparameters:  [0.01, <class 'torch.optim.sgd.SGD'>, 50, 0.001]\n",
            "[1,   200] loss: 1.668\n",
            "Accuracy of the network on the 3068 test images: 39 %\n",
            "[2,   200] loss: 1.558\n",
            "Accuracy of the network on the 3068 test images: 51 %\n",
            "[3,   200] loss: 1.264\n",
            "Accuracy of the network on the 3068 test images: 54 %\n",
            "[4,   200] loss: 1.062\n",
            "Accuracy of the network on the 3068 test images: 64 %\n",
            "[5,   200] loss: 0.946\n",
            "Accuracy of the network on the 3068 test images: 66 %\n",
            "[6,   200] loss: 0.875\n",
            "Accuracy of the network on the 3068 test images: 67 %\n",
            "[7,   200] loss: 0.815\n",
            "Accuracy of the network on the 3068 test images: 69 %\n",
            "[8,   200] loss: 0.765\n",
            "Accuracy of the network on the 3068 test images: 66 %\n",
            "[9,   200] loss: 0.725\n",
            "Accuracy of the network on the 3068 test images: 71 %\n",
            "[10,   200] loss: 0.675\n",
            "Accuracy of the network on the 3068 test images: 73 %\n",
            "[11,   200] loss: 0.640\n",
            "Accuracy of the network on the 3068 test images: 73 %\n",
            "[12,   200] loss: 0.616\n",
            "Accuracy of the network on the 3068 test images: 73 %\n",
            "[13,   200] loss: 0.583\n",
            "Accuracy of the network on the 3068 test images: 72 %\n",
            "[14,   200] loss: 0.544\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[15,   200] loss: 0.523\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[16,   200] loss: 0.498\n",
            "Accuracy of the network on the 3068 test images: 76 %\n",
            "[17,   200] loss: 0.443\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[18,   200] loss: 0.436\n",
            "Accuracy of the network on the 3068 test images: 68 %\n",
            "[19,   200] loss: 0.415\n",
            "Accuracy of the network on the 3068 test images: 73 %\n",
            "[20,   200] loss: 0.373\n",
            "Accuracy of the network on the 3068 test images: 73 %\n",
            "[21,   200] loss: 0.351\n",
            "Accuracy of the network on the 3068 test images: 73 %\n",
            "[22,   200] loss: 0.336\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[23,   200] loss: 0.278\n",
            "Accuracy of the network on the 3068 test images: 73 %\n",
            "[24,   200] loss: 0.292\n",
            "Accuracy of the network on the 3068 test images: 74 %\n",
            "[25,   200] loss: 0.258\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[26,   200] loss: 0.225\n",
            "Accuracy of the network on the 3068 test images: 71 %\n",
            "[27,   200] loss: 0.223\n",
            "Accuracy of the network on the 3068 test images: 73 %\n",
            "[28,   200] loss: 0.201\n",
            "Accuracy of the network on the 3068 test images: 71 %\n",
            "[29,   200] loss: 0.182\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[30,   200] loss: 0.158\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[31,   200] loss: 0.164\n",
            "Accuracy of the network on the 3068 test images: 71 %\n",
            "[32,   200] loss: 0.148\n",
            "Accuracy of the network on the 3068 test images: 70 %\n",
            "[33,   200] loss: 0.167\n",
            "Accuracy of the network on the 3068 test images: 73 %\n",
            "[34,   200] loss: 0.120\n",
            "Accuracy of the network on the 3068 test images: 76 %\n",
            "[35,   200] loss: 0.118\n",
            "Accuracy of the network on the 3068 test images: 71 %\n",
            "[36,   200] loss: 0.102\n",
            "Accuracy of the network on the 3068 test images: 74 %\n",
            "[37,   200] loss: 0.083\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[38,   200] loss: 0.101\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[39,   200] loss: 0.090\n",
            "Accuracy of the network on the 3068 test images: 73 %\n",
            "[40,   200] loss: 0.070\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[41,   200] loss: 0.108\n",
            "Accuracy of the network on the 3068 test images: 66 %\n",
            "[42,   200] loss: 0.090\n",
            "Accuracy of the network on the 3068 test images: 56 %\n",
            "[43,   200] loss: 0.076\n",
            "Accuracy of the network on the 3068 test images: 76 %\n",
            "[44,   200] loss: 0.019\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[45,   200] loss: 0.052\n",
            "Accuracy of the network on the 3068 test images: 74 %\n",
            "[46,   200] loss: 0.053\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[47,   200] loss: 0.060\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[48,   200] loss: 0.061\n",
            "Accuracy of the network on the 3068 test images: 71 %\n",
            "[49,   200] loss: 0.054\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[50,   200] loss: 0.015\n",
            "Accuracy of the network on the 3068 test images: 74 %\n",
            "Finished Training\n",
            "Final accuracy: 0.741199478487614\n",
            "Hyperparameters:  [0.01, <class 'torch.optim.sgd.SGD'>, 50, 0.01]\n",
            "[1,   200] loss: 1.705\n",
            "Accuracy of the network on the 3068 test images: 38 %\n",
            "[2,   200] loss: 1.542\n",
            "Accuracy of the network on the 3068 test images: 54 %\n",
            "[3,   200] loss: 1.233\n",
            "Accuracy of the network on the 3068 test images: 57 %\n",
            "[4,   200] loss: 1.051\n",
            "Accuracy of the network on the 3068 test images: 63 %\n",
            "[5,   200] loss: 0.951\n",
            "Accuracy of the network on the 3068 test images: 68 %\n",
            "[6,   200] loss: 0.884\n",
            "Accuracy of the network on the 3068 test images: 65 %\n",
            "[7,   200] loss: 0.831\n",
            "Accuracy of the network on the 3068 test images: 63 %\n",
            "[8,   200] loss: 0.807\n",
            "Accuracy of the network on the 3068 test images: 69 %\n",
            "[9,   200] loss: 0.772\n",
            "Accuracy of the network on the 3068 test images: 70 %\n",
            "[10,   200] loss: 0.747\n",
            "Accuracy of the network on the 3068 test images: 70 %\n",
            "[11,   200] loss: 0.740\n",
            "Accuracy of the network on the 3068 test images: 69 %\n",
            "[12,   200] loss: 0.690\n",
            "Accuracy of the network on the 3068 test images: 72 %\n",
            "[13,   200] loss: 0.671\n",
            "Accuracy of the network on the 3068 test images: 73 %\n",
            "[14,   200] loss: 0.663\n",
            "Accuracy of the network on the 3068 test images: 68 %\n",
            "[15,   200] loss: 0.652\n",
            "Accuracy of the network on the 3068 test images: 71 %\n",
            "[16,   200] loss: 0.624\n",
            "Accuracy of the network on the 3068 test images: 72 %\n",
            "[17,   200] loss: 0.610\n",
            "Accuracy of the network on the 3068 test images: 71 %\n",
            "[18,   200] loss: 0.609\n",
            "Accuracy of the network on the 3068 test images: 69 %\n",
            "[19,   200] loss: 0.600\n",
            "Accuracy of the network on the 3068 test images: 71 %\n",
            "[20,   200] loss: 0.602\n",
            "Accuracy of the network on the 3068 test images: 74 %\n",
            "[21,   200] loss: 0.576\n",
            "Accuracy of the network on the 3068 test images: 73 %\n",
            "[22,   200] loss: 0.562\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[23,   200] loss: 0.530\n",
            "Accuracy of the network on the 3068 test images: 74 %\n",
            "[24,   200] loss: 0.525\n",
            "Accuracy of the network on the 3068 test images: 68 %\n",
            "[25,   200] loss: 0.524\n",
            "Accuracy of the network on the 3068 test images: 67 %\n",
            "[26,   200] loss: 0.508\n",
            "Accuracy of the network on the 3068 test images: 68 %\n",
            "[27,   200] loss: 0.492\n",
            "Accuracy of the network on the 3068 test images: 66 %\n",
            "[28,   200] loss: 0.487\n",
            "Accuracy of the network on the 3068 test images: 70 %\n",
            "[29,   200] loss: 0.470\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[30,   200] loss: 0.459\n",
            "Accuracy of the network on the 3068 test images: 69 %\n",
            "[31,   200] loss: 0.436\n",
            "Accuracy of the network on the 3068 test images: 71 %\n",
            "[32,   200] loss: 0.434\n",
            "Accuracy of the network on the 3068 test images: 73 %\n",
            "[33,   200] loss: 0.446\n",
            "Accuracy of the network on the 3068 test images: 71 %\n",
            "[34,   200] loss: 0.432\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[35,   200] loss: 0.416\n",
            "Accuracy of the network on the 3068 test images: 73 %\n",
            "[36,   200] loss: 0.387\n",
            "Accuracy of the network on the 3068 test images: 67 %\n",
            "[37,   200] loss: 0.390\n",
            "Accuracy of the network on the 3068 test images: 69 %\n",
            "[38,   200] loss: 0.373\n",
            "Accuracy of the network on the 3068 test images: 71 %\n",
            "[39,   200] loss: 0.375\n",
            "Accuracy of the network on the 3068 test images: 69 %\n",
            "[40,   200] loss: 0.355\n",
            "Accuracy of the network on the 3068 test images: 68 %\n",
            "[41,   200] loss: 0.351\n",
            "Accuracy of the network on the 3068 test images: 74 %\n",
            "[42,   200] loss: 0.332\n",
            "Accuracy of the network on the 3068 test images: 64 %\n",
            "[43,   200] loss: 0.331\n",
            "Accuracy of the network on the 3068 test images: 71 %\n",
            "[44,   200] loss: 0.329\n",
            "Accuracy of the network on the 3068 test images: 67 %\n",
            "[45,   200] loss: 0.347\n",
            "Accuracy of the network on the 3068 test images: 68 %\n",
            "[46,   200] loss: 0.324\n",
            "Accuracy of the network on the 3068 test images: 60 %\n",
            "[47,   200] loss: 0.308\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[48,   200] loss: 0.291\n",
            "Accuracy of the network on the 3068 test images: 74 %\n",
            "[49,   200] loss: 0.267\n",
            "Accuracy of the network on the 3068 test images: 71 %\n",
            "[50,   200] loss: 0.279\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "Finished Training\n",
            "Final accuracy: 0.7503259452411994\n",
            "Hyperparameters:  [0.05, <class 'torch.optim.sgd.SGD'>, 50, 0.001]\n",
            "[1,   200] loss: 1.566\n",
            "Accuracy of the network on the 3068 test images: 55 %\n",
            "[2,   200] loss: 1.636\n",
            "Accuracy of the network on the 3068 test images: 52 %\n",
            "[3,   200] loss: 1.260\n",
            "Accuracy of the network on the 3068 test images: 59 %\n",
            "[4,   200] loss: 1.037\n",
            "Accuracy of the network on the 3068 test images: 64 %\n",
            "[5,   200] loss: 0.928\n",
            "Accuracy of the network on the 3068 test images: 56 %\n",
            "[6,   200] loss: 0.886\n",
            "Accuracy of the network on the 3068 test images: 67 %\n",
            "[7,   200] loss: 0.831\n",
            "Accuracy of the network on the 3068 test images: 68 %\n",
            "[8,   200] loss: 0.776\n",
            "Accuracy of the network on the 3068 test images: 71 %\n",
            "[9,   200] loss: 0.718\n",
            "Accuracy of the network on the 3068 test images: 72 %\n",
            "[10,   200] loss: 0.676\n",
            "Accuracy of the network on the 3068 test images: 73 %\n",
            "[11,   200] loss: 0.639\n",
            "Accuracy of the network on the 3068 test images: 71 %\n",
            "[12,   200] loss: 0.605\n",
            "Accuracy of the network on the 3068 test images: 69 %\n",
            "[13,   200] loss: 0.576\n",
            "Accuracy of the network on the 3068 test images: 74 %\n",
            "[14,   200] loss: 0.543\n",
            "Accuracy of the network on the 3068 test images: 74 %\n",
            "[15,   200] loss: 0.526\n",
            "Accuracy of the network on the 3068 test images: 66 %\n",
            "[16,   200] loss: 0.485\n",
            "Accuracy of the network on the 3068 test images: 73 %\n",
            "[17,   200] loss: 0.454\n",
            "Accuracy of the network on the 3068 test images: 72 %\n",
            "[18,   200] loss: 0.431\n",
            "Accuracy of the network on the 3068 test images: 67 %\n",
            "[19,   200] loss: 0.414\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[20,   200] loss: 0.379\n",
            "Accuracy of the network on the 3068 test images: 73 %\n",
            "[21,   200] loss: 0.366\n",
            "Accuracy of the network on the 3068 test images: 73 %\n",
            "[22,   200] loss: 0.343\n",
            "Accuracy of the network on the 3068 test images: 74 %\n",
            "[23,   200] loss: 0.315\n",
            "Accuracy of the network on the 3068 test images: 70 %\n",
            "[24,   200] loss: 0.312\n",
            "Accuracy of the network on the 3068 test images: 74 %\n",
            "[25,   200] loss: 0.280\n",
            "Accuracy of the network on the 3068 test images: 71 %\n",
            "[26,   200] loss: 0.272\n",
            "Accuracy of the network on the 3068 test images: 76 %\n",
            "[27,   200] loss: 0.263\n",
            "Accuracy of the network on the 3068 test images: 72 %\n",
            "[28,   200] loss: 0.230\n",
            "Accuracy of the network on the 3068 test images: 74 %\n",
            "[29,   200] loss: 0.227\n",
            "Accuracy of the network on the 3068 test images: 72 %\n",
            "[30,   200] loss: 0.205\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[31,   200] loss: 0.498\n",
            "Accuracy of the network on the 3068 test images: 62 %\n",
            "[32,   200] loss: 0.229\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[33,   200] loss: 0.199\n",
            "Accuracy of the network on the 3068 test images: 73 %\n",
            "[34,   200] loss: 0.190\n",
            "Accuracy of the network on the 3068 test images: 71 %\n",
            "[35,   200] loss: 0.170\n",
            "Accuracy of the network on the 3068 test images: 70 %\n",
            "[36,   200] loss: 0.159\n",
            "Accuracy of the network on the 3068 test images: 70 %\n",
            "[37,   200] loss: 0.153\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[38,   200] loss: 0.142\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[39,   200] loss: 0.116\n",
            "Accuracy of the network on the 3068 test images: 73 %\n",
            "[40,   200] loss: 0.153\n",
            "Accuracy of the network on the 3068 test images: 72 %\n",
            "[41,   200] loss: 0.109\n",
            "Accuracy of the network on the 3068 test images: 70 %\n",
            "[42,   200] loss: 0.137\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[43,   200] loss: 0.122\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[44,   200] loss: 0.164\n",
            "Accuracy of the network on the 3068 test images: 74 %\n",
            "[45,   200] loss: 0.090\n",
            "Accuracy of the network on the 3068 test images: 74 %\n",
            "[46,   200] loss: 0.079\n",
            "Accuracy of the network on the 3068 test images: 72 %\n",
            "[47,   200] loss: 0.162\n",
            "Accuracy of the network on the 3068 test images: 67 %\n",
            "[48,   200] loss: 0.145\n",
            "Accuracy of the network on the 3068 test images: 73 %\n",
            "[49,   200] loss: 0.154\n",
            "Accuracy of the network on the 3068 test images: 74 %\n",
            "[50,   200] loss: 0.135\n",
            "Accuracy of the network on the 3068 test images: 73 %\n",
            "Finished Training\n",
            "Final accuracy: 0.733702737940026\n",
            "Hyperparameters:  [0.05, <class 'torch.optim.sgd.SGD'>, 50, 0.01]\n",
            "[1,   200] loss: 1.575\n",
            "Accuracy of the network on the 3068 test images: 49 %\n",
            "[2,   200] loss: 1.684\n",
            "Accuracy of the network on the 3068 test images: 38 %\n",
            "[3,   200] loss: 1.519\n",
            "Accuracy of the network on the 3068 test images: 42 %\n",
            "[4,   200] loss: 1.335\n",
            "Accuracy of the network on the 3068 test images: 55 %\n",
            "[5,   200] loss: 1.227\n",
            "Accuracy of the network on the 3068 test images: 26 %\n",
            "[6,   200] loss: 1.166\n",
            "Accuracy of the network on the 3068 test images: 61 %\n",
            "[7,   200] loss: 1.115\n",
            "Accuracy of the network on the 3068 test images: 58 %\n",
            "[8,   200] loss: 1.071\n",
            "Accuracy of the network on the 3068 test images: 59 %\n",
            "[9,   200] loss: 1.075\n",
            "Accuracy of the network on the 3068 test images: 61 %\n",
            "[10,   200] loss: 1.041\n",
            "Accuracy of the network on the 3068 test images: 65 %\n",
            "[11,   200] loss: 0.995\n",
            "Accuracy of the network on the 3068 test images: 63 %\n",
            "[12,   200] loss: 1.004\n",
            "Accuracy of the network on the 3068 test images: 64 %\n",
            "[13,   200] loss: 0.990\n",
            "Accuracy of the network on the 3068 test images: 66 %\n",
            "[14,   200] loss: 0.995\n",
            "Accuracy of the network on the 3068 test images: 62 %\n",
            "[15,   200] loss: 0.991\n",
            "Accuracy of the network on the 3068 test images: 47 %\n",
            "[16,   200] loss: 0.959\n",
            "Accuracy of the network on the 3068 test images: 67 %\n",
            "[17,   200] loss: 0.969\n",
            "Accuracy of the network on the 3068 test images: 68 %\n",
            "[18,   200] loss: 0.956\n",
            "Accuracy of the network on the 3068 test images: 60 %\n",
            "[19,   200] loss: 0.943\n",
            "Accuracy of the network on the 3068 test images: 64 %\n",
            "[20,   200] loss: 0.951\n",
            "Accuracy of the network on the 3068 test images: 66 %\n",
            "[21,   200] loss: 0.960\n",
            "Accuracy of the network on the 3068 test images: 60 %\n",
            "[22,   200] loss: 0.962\n",
            "Accuracy of the network on the 3068 test images: 64 %\n",
            "[23,   200] loss: 0.938\n",
            "Accuracy of the network on the 3068 test images: 64 %\n",
            "[24,   200] loss: 0.946\n",
            "Accuracy of the network on the 3068 test images: 67 %\n",
            "[25,   200] loss: 0.944\n",
            "Accuracy of the network on the 3068 test images: 68 %\n",
            "[26,   200] loss: 0.934\n",
            "Accuracy of the network on the 3068 test images: 67 %\n",
            "[27,   200] loss: 0.930\n",
            "Accuracy of the network on the 3068 test images: 57 %\n",
            "[28,   200] loss: 0.909\n",
            "Accuracy of the network on the 3068 test images: 67 %\n",
            "[29,   200] loss: 0.926\n",
            "Accuracy of the network on the 3068 test images: 62 %\n",
            "[30,   200] loss: 0.957\n",
            "Accuracy of the network on the 3068 test images: 65 %\n",
            "[31,   200] loss: 0.913\n",
            "Accuracy of the network on the 3068 test images: 67 %\n",
            "[32,   200] loss: 0.931\n",
            "Accuracy of the network on the 3068 test images: 69 %\n",
            "[33,   200] loss: 0.917\n",
            "Accuracy of the network on the 3068 test images: 66 %\n",
            "[34,   200] loss: 0.905\n",
            "Accuracy of the network on the 3068 test images: 56 %\n",
            "[35,   200] loss: 0.917\n",
            "Accuracy of the network on the 3068 test images: 67 %\n",
            "[36,   200] loss: 0.898\n",
            "Accuracy of the network on the 3068 test images: 66 %\n",
            "[37,   200] loss: 0.919\n",
            "Accuracy of the network on the 3068 test images: 50 %\n",
            "[38,   200] loss: 0.929\n",
            "Accuracy of the network on the 3068 test images: 67 %\n",
            "[39,   200] loss: 0.906\n",
            "Accuracy of the network on the 3068 test images: 59 %\n",
            "[40,   200] loss: 0.893\n",
            "Accuracy of the network on the 3068 test images: 58 %\n",
            "[41,   200] loss: 0.889\n",
            "Accuracy of the network on the 3068 test images: 64 %\n",
            "[42,   200] loss: 0.898\n",
            "Accuracy of the network on the 3068 test images: 68 %\n",
            "[43,   200] loss: 0.899\n",
            "Accuracy of the network on the 3068 test images: 63 %\n",
            "[44,   200] loss: 0.938\n",
            "Accuracy of the network on the 3068 test images: 57 %\n",
            "[45,   200] loss: 0.910\n",
            "Accuracy of the network on the 3068 test images: 64 %\n",
            "[46,   200] loss: 0.905\n",
            "Accuracy of the network on the 3068 test images: 69 %\n",
            "[47,   200] loss: 0.890\n",
            "Accuracy of the network on the 3068 test images: 64 %\n",
            "[48,   200] loss: 0.900\n",
            "Accuracy of the network on the 3068 test images: 64 %\n",
            "[49,   200] loss: 0.892\n",
            "Accuracy of the network on the 3068 test images: 67 %\n",
            "[50,   200] loss: 0.880\n",
            "Accuracy of the network on the 3068 test images: 61 %\n",
            "Finished Training\n",
            "Final accuracy: 0.6157105606258149\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siSYr2alsEWi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hyperparameters = np.array(hyperparameters)\n",
        "accuracies = np.array(accuracies)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_ENgVk7nopZ",
        "colab_type": "code",
        "outputId": "b2b730f7-e60a-4c5a-9cad-80aa79bd50bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "\n",
        "hs_filename = os.path.join(data_dir,'grid_search.npz')\n",
        "if not skip_training:\n",
        "    try:\n",
        "        do_save = input('Do you want to save the results of hyperparameter search (type yes to confirm)? ').lower()\n",
        "        if do_save == 'yes':\n",
        "            np.savez(hs_filename,\n",
        "                     hyperparameters=hyperparameters,\n",
        "                     accuracies=accuracies)\n",
        "            print('Results saved to %s' % hs_filename)\n",
        "        else:\n",
        "            print('Results not saved')\n",
        "    except:\n",
        "        raise Exception('The notebook should be run or validated with skip_training=True.')\n",
        "else:\n",
        "    rs = np.load(hs_filename, allow_pickle=True)\n",
        "    hyperparameters = rs['hyperparameters']\n",
        "    accuracies = rs['accuracies']\n",
        "    print('Results loaded from %s' % hs_filename)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results loaded from /content/gdrive/My Drive/DLProject/grid_search.npz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyWoRWaPrrC1",
        "colab_type": "code",
        "outputId": "1da20cd1-9d44-4f1b-de87-482244cc3045",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "print('lrate_range optimizers n_epochs weightdecay')\n",
        "ix = accuracies.argsort()[-1::-1]\n",
        "for (lrate, opt, n_epoch, wd), accuracy in zip(hyperparameters[ix], accuracies[ix]):\n",
        "    print('%6.3f %s %2d %7.3f %8.3f' % (lrate, opt, n_epoch, wd, accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lrate_range optimizers n_epochs weightdecay\n",
            " 0.005 <class 'torch.optim.sgd.SGD'> 50   0.001    0.763\n",
            " 0.005 <class 'torch.optim.sgd.SGD'> 50   0.010    0.760\n",
            " 0.010 <class 'torch.optim.sgd.SGD'> 50   0.010    0.750\n",
            " 0.010 <class 'torch.optim.sgd.SGD'> 50   0.001    0.741\n",
            " 0.050 <class 'torch.optim.sgd.SGD'> 50   0.001    0.734\n",
            " 0.050 <class 'torch.optim.sgd.SGD'> 50   0.010    0.616\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unXtrBHUss4C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Another Fine Tuning Test\n",
        "\n",
        "lrate_range = [0.002, 0.005]  \n",
        "optimizers = [optim.SGD, optim.Adam]\n",
        "weightdecay = [0.001, 0.005]\n",
        "\n",
        "hyperparameters = []\n",
        "accuracies = []\n",
        "\n",
        "if not skip_training:\n",
        "    for (lrate, opt, n_epoch, wd) in grid_search(lrate_range, optimizers, n_epochs, weightdecay):\n",
        "        hyperparameters.append([lrate, opt, n_epoch, wd])\n",
        "        print('Hyperparameters: ', hyperparameters[-1])\n",
        "        network, test_accuracy_history = train(lrate, opt,  n_epoch, wd)\n",
        "        accuracies.append(test_accuracy_history[-1])\n",
        "        print('Final accuracy:', accuracies[-1])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGWoZ1u0_NM4",
        "colab_type": "text"
      },
      "source": [
        "# Data Transformation \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y43DsDgKtexO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "TRAIN_DATA_PATH = \"/content/gdrive/My Drive/DLProject/train\"\n",
        "TEST_DATA_PATH = \"/content/gdrive/My Drive/DLProject/test\"\n",
        "TRANSFORM_IMG_TRAIN = transforms.Compose([\n",
        "    transforms.Resize(100,100),\n",
        "    transforms.RandomHorizontalFlip( p = 0.2),\n",
        "    transforms.ColorJitter(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,), (0.5,))\n",
        "    ])\n",
        "\n",
        "TRANSFORM_IMG_TEST = transforms.Compose([\n",
        "    transforms.Resize(100,100),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,), (0.5,))\n",
        "    ])\n",
        "\n",
        "\n",
        "\n",
        "train_data = torchvision.datasets.ImageFolder(root=TRAIN_DATA_PATH, transform=TRANSFORM_IMG_TRAIN)\n",
        "train_loader = data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "test_data = torchvision.datasets.ImageFolder(root=TEST_DATA_PATH, transform=TRANSFORM_IMG_TEST)\n",
        "test_loader  = data.DataLoader(test_data, batch_size=5, shuffle=False) \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fzm8tNCd2boQ",
        "colab_type": "code",
        "outputId": "2a0e3465-ef29-4a97-cd84-e6b743650bf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1475
        }
      },
      "source": [
        "skip_training = False \n",
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "net = VGG()\n",
        "net.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.005, weight_decay = 0.001)\n",
        "n_epochs = 50\n",
        "\n",
        "net.train()\n",
        "for epoch in range(n_epochs):\n",
        "    running_loss = 0.0\n",
        "    print_every = 200  # mini-batches\n",
        "    for i, (inputs, labels) in enumerate(train_loader, 0):\n",
        "        # Transfer to GPU\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        \n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if (i % print_every) == (print_every-1):\n",
        "            print('[%d, %5d] loss: %.3f' % (epoch+1, i+1, running_loss/print_every))\n",
        "            running_loss = 0.0\n",
        "        if skip_training:\n",
        "            break\n",
        "\n",
        "    # Print accuracy after every epoch\n",
        "    accuracy = compute_accuracy(net, test_loader)\n",
        "    print('Accuracy of the network on the 3068 test images: %d %%' % (100 * accuracy))\n",
        "\n",
        "    if skip_training:\n",
        "        break\n",
        "\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   200] loss: 1.735\n",
            "Accuracy of the network on the 3068 test images: 38 %\n",
            "[2,   200] loss: 1.562\n",
            "Accuracy of the network on the 3068 test images: 46 %\n",
            "[3,   200] loss: 1.357\n",
            "Accuracy of the network on the 3068 test images: 56 %\n",
            "[4,   200] loss: 1.211\n",
            "Accuracy of the network on the 3068 test images: 55 %\n",
            "[5,   200] loss: 1.083\n",
            "Accuracy of the network on the 3068 test images: 59 %\n",
            "[6,   200] loss: 0.992\n",
            "Accuracy of the network on the 3068 test images: 56 %\n",
            "[7,   200] loss: 0.938\n",
            "Accuracy of the network on the 3068 test images: 61 %\n",
            "[8,   200] loss: 0.868\n",
            "Accuracy of the network on the 3068 test images: 63 %\n",
            "[9,   200] loss: 0.834\n",
            "Accuracy of the network on the 3068 test images: 72 %\n",
            "[10,   200] loss: 0.784\n",
            "Accuracy of the network on the 3068 test images: 71 %\n",
            "[11,   200] loss: 0.747\n",
            "Accuracy of the network on the 3068 test images: 68 %\n",
            "[12,   200] loss: 0.727\n",
            "Accuracy of the network on the 3068 test images: 71 %\n",
            "[13,   200] loss: 0.709\n",
            "Accuracy of the network on the 3068 test images: 73 %\n",
            "[14,   200] loss: 0.679\n",
            "Accuracy of the network on the 3068 test images: 65 %\n",
            "[15,   200] loss: 0.653\n",
            "Accuracy of the network on the 3068 test images: 72 %\n",
            "[16,   200] loss: 0.630\n",
            "Accuracy of the network on the 3068 test images: 72 %\n",
            "[17,   200] loss: 0.623\n",
            "Accuracy of the network on the 3068 test images: 73 %\n",
            "[18,   200] loss: 0.590\n",
            "Accuracy of the network on the 3068 test images: 72 %\n",
            "[19,   200] loss: 0.564\n",
            "Accuracy of the network on the 3068 test images: 71 %\n",
            "[20,   200] loss: 0.544\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[21,   200] loss: 0.522\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[22,   200] loss: 0.520\n",
            "Accuracy of the network on the 3068 test images: 73 %\n",
            "[23,   200] loss: 0.498\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[24,   200] loss: 0.476\n",
            "Accuracy of the network on the 3068 test images: 72 %\n",
            "[25,   200] loss: 0.473\n",
            "Accuracy of the network on the 3068 test images: 73 %\n",
            "[26,   200] loss: 0.444\n",
            "Accuracy of the network on the 3068 test images: 76 %\n",
            "[27,   200] loss: 0.441\n",
            "Accuracy of the network on the 3068 test images: 74 %\n",
            "[28,   200] loss: 0.428\n",
            "Accuracy of the network on the 3068 test images: 76 %\n",
            "[29,   200] loss: 0.408\n",
            "Accuracy of the network on the 3068 test images: 74 %\n",
            "[30,   200] loss: 0.405\n",
            "Accuracy of the network on the 3068 test images: 77 %\n",
            "[31,   200] loss: 0.377\n",
            "Accuracy of the network on the 3068 test images: 76 %\n",
            "[32,   200] loss: 0.370\n",
            "Accuracy of the network on the 3068 test images: 76 %\n",
            "[33,   200] loss: 0.357\n",
            "Accuracy of the network on the 3068 test images: 78 %\n",
            "[34,   200] loss: 0.335\n",
            "Accuracy of the network on the 3068 test images: 76 %\n",
            "[35,   200] loss: 0.346\n",
            "Accuracy of the network on the 3068 test images: 77 %\n",
            "[36,   200] loss: 0.318\n",
            "Accuracy of the network on the 3068 test images: 77 %\n",
            "[37,   200] loss: 0.311\n",
            "Accuracy of the network on the 3068 test images: 76 %\n",
            "[38,   200] loss: 0.301\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[39,   200] loss: 0.293\n",
            "Accuracy of the network on the 3068 test images: 77 %\n",
            "[40,   200] loss: 0.280\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[41,   200] loss: 0.261\n",
            "Accuracy of the network on the 3068 test images: 77 %\n",
            "[42,   200] loss: 0.262\n",
            "Accuracy of the network on the 3068 test images: 75 %\n",
            "[43,   200] loss: 0.247\n",
            "Accuracy of the network on the 3068 test images: 77 %\n",
            "[44,   200] loss: 0.239\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKLGCFOQyQc_",
        "colab_type": "text"
      },
      "source": [
        "# VGG  2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GKae-z0yPhs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VGG2(nn.Module):\n",
        "    def __init__(self, n_channels=32):\n",
        "\n",
        "        super(VGG2, self).__init__()\n",
        "        n = n_channels\n",
        "        #Block 1\n",
        "        self.conv11 = nn.Conv2d(3, n, 3, padding = 1) #Change 1 to 3\n",
        "        self.conv11_bn = nn.BatchNorm2d(n)\n",
        "        self.conv12 = nn.Conv2d(n, n, 3, padding = 1)\n",
        "        self.conv12_bn = nn.BatchNorm2d(n)        \n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride = 2)\n",
        "        \n",
        "        #Block 2\n",
        "        self.conv21 = nn.Conv2d(n, 2*n, 3, padding = 1)\n",
        "        self.conv21_bn = nn.BatchNorm2d(2*n)\n",
        "        self.conv22 = nn.Conv2d(2*n, 2*n, 3, padding = 1)\n",
        "        self.conv22_bn = nn.BatchNorm2d(2*n)\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride = 2)       \n",
        "\n",
        "        #Block 3\n",
        "        self.conv31 = nn.Conv2d(2*n, 4*n, 3, padding = 1)\n",
        "        self.conv31_bn = nn.BatchNorm2d(4*n)\n",
        "\n",
        "        #Block 4\n",
        "        self.conv41 = nn.Conv2d(4*n, 8*n, 1)\n",
        "        self.conv41_bn = nn.BatchNorm2d(8*n)\n",
        "        \n",
        "        #Block 5\n",
        "        self.conv51 = nn.Conv2d(8*n, 8*n, 1)\n",
        "        self.conv51_bn = nn.BatchNorm2d(8*n)\n",
        "        \n",
        "        self.avgpool = nn.AvgPool2d(kernel_size = 5)\n",
        "        \n",
        "        self.fc1 = nn.Linear(6400, 256)\n",
        "        self.fc2 = nn.Linear(256, 7)\n",
        "\n",
        "\n",
        "    def forward(self, x, verbose=False):\n",
        "        if verbose: print(x.shape)\n",
        "        x = F.relu(self.conv11_bn(self.conv11(x)))\n",
        "        x = F.relu(self.conv12_bn(self.conv12(x)))\n",
        "\n",
        "        if verbose: print(\"conv1\", x.shape)\n",
        "        x = self.maxpool1(x)\n",
        "        if verbose: print('maxpool1:', x.shape)\n",
        "\n",
        "        x = F.relu(self.conv21_bn(self.conv21(x)))\n",
        "        x = F.relu(self.conv22_bn(self.conv22(x)))\n",
        "        if verbose: print('conv2', x.shape)\n",
        "        x = self.maxpool2(x)\n",
        "        if verbose: print('maxpool2:', x.shape)\n",
        "        \n",
        "        x = F.relu(self.conv31_bn(self.conv31(x)))\n",
        "        if verbose: print('conv3', x.shape)\n",
        " \n",
        "        x = F.relu(self.conv41_bn(self.conv41(x)))\n",
        "        if verbose: print('conv4',x.shape)\n",
        "\n",
        "        x = F.relu(self.conv51_bn(self.conv51(x)))\n",
        "        if verbose: print('conv5',x.shape)\n",
        "          \n",
        "        x = self.avgpool(x)\n",
        "        if verbose: print('avgpool:', x.shape)\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        if verbose: print('x flatten:', x.shape)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        if verbose: print('out :', x.shape)\n",
        "\n",
        "        return x "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gA9mQiVkyb_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "net = VGG()\n",
        "net.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.005, weight_decay = 0.001)\n",
        "n_epochs = 50\n",
        "\n",
        "net.train()\n",
        "for epoch in range(n_epochs):\n",
        "    running_loss = 0.0\n",
        "    print_every = 200  # mini-batches\n",
        "    for i, (inputs, labels) in enumerate(train_loader, 0):\n",
        "        # Transfer to GPU\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if (i % print_every) == (print_every-1):\n",
        "            print('[%d, %5d] loss: %.3f' % (epoch+1, i+1, running_loss/print_every))\n",
        "            running_loss = 0.0\n",
        "        if skip_training:\n",
        "            break\n",
        "\n",
        "    # Print accuracy after every epoch\n",
        "    accuracy = compute_accuracy(net, test_loader)\n",
        "    print('Accuracy of the network on the 3068 test images: %d %%' % (100 * accuracy))\n",
        "\n",
        "    if skip_training:\n",
        "        break\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTPdeXyGygVN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Save model \n",
        "filename = os.path.join(data_dir,'vgg_2.pth')\n",
        "if not skip_training:\n",
        "    try:\n",
        "        do_save = input('Do you want to save the model (type yes to confirm)? ').lower()\n",
        "        if do_save == 'yes':\n",
        "            torch.save(net.state_dict(), filename)\n",
        "            print('Model saved to %s' % filename)\n",
        "        else:\n",
        "            print('Model not saved')\n",
        "    except:\n",
        "        raise Exception('The notebook should be run or validated with skip_training=True.')\n",
        "else:\n",
        "    net = VGG()\n",
        "    net.load_state_dict(torch.load(filename, map_location=lambda storage, loc: storage))\n",
        "    net.to(device)\n",
        "    print('Model loaded from %s' % filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7DNajF3y0Xa",
        "colab_type": "text"
      },
      "source": [
        "#Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFWW4vaxyjsF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(compute_accuracy(net, test_loader))\n",
        "confusion_matrix(net, test_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-88lEw1ynMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = ['anger', 'disgust', 'fear', 'happiness', 'neutral', 'sadness', 'surprise']\n",
        "\n",
        "    \n",
        "# Display random images from the test set, the ground truth labels and the network's predictions\n",
        "net.eval()\n",
        "with torch.no_grad():\n",
        "       dataiter = iter(test_loader)\n",
        "       images, labels = dataiter.next()\n",
        "       outputs = net(images)\n",
        "       out = torchvision.utils.make_grid(images)\n",
        "       predicted = torch.argmax(outputs.data, 1)\n",
        "       imshow(out)     \n",
        "       print('Ground truth labels: ', ' '.join('%10s' % classes[labels[j]] for j in range(5)))\n",
        "       print('Predictions:         ', ' '.join('%10s' % classes[j] for j in predicted))\n",
        "       \n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}